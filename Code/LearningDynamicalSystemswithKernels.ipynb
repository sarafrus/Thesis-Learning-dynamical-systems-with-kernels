{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8sEg0bQzvrk"
      },
      "source": [
        "Sara Frusone\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAySh282zvrr"
      },
      "source": [
        "# LEARNING DYNAICAL SYSTEMS WITH KERNELS\n",
        "# Logistic Map Notebook\n",
        "\n",
        "Predicting values generating logistic maps with different non-periodicity/periodicity.\n",
        "\n",
        "### Logistic map theory overview\n",
        "The logistic map was derived from a differential equation describing population growth, popularized by Robert May. The dynamical equation is as follows:\n",
        "\n",
        "$x_{n+1}=rx_{n}(1âˆ’x_{n})$\n",
        "\n",
        "where $r$ can be considered akin to a growth rate, $x_{n+1}$ is the population next year, and $x_{n}$ is the current population. Population ranges between 0 and 1, and signifies the proportion of the maximum population. What happens to population over time at a fixed $r$ value?\n",
        "\n",
        "\n",
        "As $r$ increases, the periodicity increases until it becomes infinite, and infinite periodicity is equivalent to aperiodicity. This occurs via period doubling: as can be seen clearly from the logistic map, one period splits into two, which split into four, which split into eight etc. This period doubling occurs with less and less increase in r such that an infinite period is reached within a finite increase in $r$, and at this point the map is aperiodic. This occurs whenever there is a transition from periodicity to aperiodicity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVqCOC-rzvrv"
      },
      "source": [
        "Importing all libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMhPQW45zvrw"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np \n",
        "from numpy import arange\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import absolute\n",
        "\n",
        "import pandas as pd  \n",
        "from pandas import read_csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot as plt \n",
        "plt.rcParams.update({'font.size': 22}) #enlarge plot font\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['lines.linewidth'] = 4\n",
        "mpl.rcParams['legend.fontsize'] = 15\n",
        "mpl.rcParams['xtick.labelsize'] = 15\n",
        "mpl.rcParams['ytick.labelsize'] = 15\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pylab as pl\n",
        "from decimal import Decimal\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_friedman2\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "from sklearn.gaussian_process.kernels import ExpSineSquared, RationalQuadratic ,Matern ,RBF, ConstantKernel, DotProduct, WhiteKernel\n",
        "# https://scikit-learn.org/stable/modules/gaussian_process.html\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d54-enwzvrz"
      },
      "source": [
        "# RIDGE REGRESSION\n",
        "Let us consider the dataset generated by the logistic map implemented above, in the different setting (stationary and not stationary).\n",
        "Let us generate the dataset and plotting it in order to check the stationarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2DSsPZLzvr0"
      },
      "outputs": [],
      "source": [
        "def Dataset_generator(r, steps):\n",
        "    # initialize an array of 0s and specify starting values and r constant\n",
        "    x = np.zeros(steps + 1)\n",
        "    y = np.zeros(steps + 1)\n",
        "    x[0], y[0] = 0, 0.4\n",
        "    dataset= []\n",
        "    dataset_y= []\n",
        "\n",
        "\n",
        "    # loop over the steps and replace array values with calculations\n",
        "    for i in range(steps):\n",
        "        y[i+1] = r * y[i] * (1 - y[i])\n",
        "        dataset.append((y[i],y[i+1])) #points should be (y_1, y_2), (y_2,y_3)\n",
        "        dataset_y.append(y[i+1])\n",
        "    # print(len(dataset_y))\n",
        "    # print(len(dataset))\n",
        "\n",
        "    \n",
        "    \n",
        "    return dataset, dataset_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two functions are implemented to plot the dataset (they differ for the grid representation)"
      ],
      "metadata": {
        "id": "xKxO8W1UBGPl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8YocB_zwd3M"
      },
      "outputs": [],
      "source": [
        "def DatasetPlotter1(r, steps, dataset, dataset_y):\n",
        "# plot the figure!\n",
        "    fig, ax = plt.subplots(1,2, figsize=(25,5))\n",
        "    \n",
        "    ax[0].plot(dataset_y,  alpha=0.5)\n",
        "    ax[0].set(xlabel='Index', ylabel='Function value')\n",
        "    ax[0].set_title('Dataset plot with r: %s' % r)\n",
        "    ax[0].grid(visible=True, axis='both')\n",
        "    \n",
        "        \n",
        "            \n",
        "    # plot the figure(y_1, y_2), (y_2,y_3)\n",
        "    flat_dataset_X = np.array([elem[0] for elem in dataset])[:,None]\n",
        "    flat_dataset_y= np.array([elem[1] for elem in dataset])[:,None] #dataset_y\n",
        "    \n",
        "    ax[1].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "   \n",
        "    ax[1].set_yscale('log')\n",
        "    ax[1].set_xscale('log')\n",
        "    #ax[1].ticklabel_format(axis='y', style='sci',scilimits=(0,0))\n",
        "    ax[1].set_title('Dataset plot with r: %s' % r)\n",
        "    ax[1].grid(visible=True,which='both', axis='both')\n",
        "    \n",
        "    l1= ax[1].scatter(flat_dataset_X,flat_dataset_y)\n",
        "    ax[1].legend([l1],[\"datset\"], loc= \"best\")\n",
        "    plt.show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1tdoFVETv0S"
      },
      "outputs": [],
      "source": [
        "def DatasetPlotter2(r, steps, dataset, dataset_y):\n",
        "# plot the figure!\n",
        "    fig, ax = plt.subplots(1,2, figsize=(25,5))\n",
        "    \n",
        "    ax[0].plot(dataset_y,  alpha=0.5)\n",
        "    ax[0].set(xlabel='Index', ylabel='Function value')\n",
        "    ax[0].set_title('Dataset plot with r: %s' % r)\n",
        "    ax[0].grid()\n",
        "     \n",
        "     \n",
        "            \n",
        "    # plot the figure(y_1, y_2), (y_2,y_3)\n",
        "    flat_dataset_X = np.array([elem[0] for elem in dataset])[:,None]\n",
        "    flat_dataset_y= np.array([elem[1] for elem in dataset])[:,None] #dataset_y\n",
        "    \n",
        "    ax[1].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "   \n",
        "    ax[1].set_yscale('log')\n",
        "    ax[1].set_xscale('log')\n",
        "    ax[1].set_title('Dataset plot with r: %s' % r)\n",
        "    ax[1].grid()\n",
        "    \n",
        "    l1= ax[1].scatter(flat_dataset_X,flat_dataset_y) \n",
        "    ax[1].legend([l1],[\"datset\"], loc= \"best\")\n",
        "    plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZMoZs3uzvr1"
      },
      "source": [
        "The Mean Absolute Percentage Error (MAPE) is one of the most commonly used KPIs to measure forecast accuracy.\n",
        "\n",
        "MAPE is the sum of the individual absolute errors divided by the demand (each period separately). It is the average of the percentage errors.\n",
        "$$\n",
        "\\mathrm{MAPE}=\\frac{100 \\%}{n} \\sum_{i=1}^n\\left|\\frac{Y_i-\\hat{Y}_i}{Y_i}\\right|\n",
        "$$\n",
        "##### Remark\n",
        "MAPE can be problematic. Most pointedly, it can cause division-by-zero errors. My guess is that this is why it is not included in the sklearn metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73rQMpjYzvr2"
      },
      "outputs": [],
      "source": [
        "#Defining MAPE function\n",
        "def MAPE(Y_true,Y_Predicted):\n",
        "    mape = np.mean(np.abs((Y_true - Y_Predicted)/Y_true))*100\n",
        "    return mape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nkMdVJTzvr3"
      },
      "source": [
        "#### MAD error\n",
        "Mean absolute deviation (MAD) is another commonly used forecasting metric. This metric shows how large an error, on average, you have in your forecast. However, as the MAD metric gives you the average error in units, it is not very useful for comparisons.\n",
        "\n",
        "$$\n",
        "\\text { MAD }=\\frac{1}{n} \\sum_{i=1}^n \\mid Y_i-\\hat{Y}_i\\mid\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "439NhwtJ3N8r"
      },
      "source": [
        "### MSE\n",
        "\n",
        "The MSE either assesses the quality of a predictor (i.e., a function mapping arbitrary inputs to a sample of values of some random variable), or of an estimator MSE differs according to whether one is describing a predictor or an estimator.\n",
        "Predictor with $\\hat{Y}$ being the predicted values (e.g. as from a least-squares fit), then the within-sample MSE of the predictor is computed as\n",
        "$$\n",
        "\\mathrm{MSE}=\\frac{1}{n} \\sum_{i=1}^n\\left(Y_i-\\hat{Y}_i\\right)^2\n",
        "$$\n",
        "In other words, the MSE is the mean $\\left(\\frac{1}{n} \\sum_{i=1}^n\\right)$ of the squares of the errors $\\left(Y_i-\\hat{Y}_i\\right)^2$. This is an easily computable quantity for a particular sample (and hence is sample-dependent).\n",
        "\n",
        "\n",
        "It is provided by the library directly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CawxjaZ4zvr4"
      },
      "source": [
        "#### Splitting \n",
        "\n",
        "Now we try different splitting of the dataset in train and test such as 50/50 and 80/20, 90/10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G-Atvt5zvr4"
      },
      "outputs": [],
      "source": [
        "#splitting function that given data, splits them according to the settled percentage pecentages, \n",
        "def split(X,y, test_size): #from 0 to 1\n",
        "    train_size= 1-test_size\n",
        "    X_train= X[:int(len(X)*train_size)]\n",
        "    X_test= X[int(len(X)*train_size):]\n",
        "    y_train= y[:int(len(y)*train_size)]\n",
        "    y_test= y[int(len(X)*train_size):]  \n",
        "    return X_train, X_test, y_train, y_test  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lre4dWNXzvr5"
      },
      "source": [
        "Let us apply the ridge regression model to the dataset\n",
        "Let us plot the real value and the the predicted \n",
        "\n",
        "It is very important the way we select the kernels since it strongly affects the forecast\n",
        "manually select the best parameter: Select an appropriate value for alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb0NEKzVFDp-"
      },
      "outputs": [],
      "source": [
        "#define a function that acts ridge regression, given a kernel alpha and splitted data \n",
        "\n",
        "def RIDGE(X_train, X_test, y_train, y_test,Kernel, alpha):\n",
        "    \n",
        "    print('Selected kernel: ' +str(Kernel))\n",
        "\n",
        "    #model\n",
        "    model = KernelRidge(alpha,kernel=Kernel).fit(X_train, y_train) \n",
        "    #compute predictions\n",
        "    pred_train= model.predict(X_train)\n",
        "    pred_test= model.predict(X_test) \n",
        "   \n",
        "    #train\n",
        "    mape_train = MAPE(y_train, pred_train)\n",
        "    mse_train = mean_squared_error(pred_train,y_train)\n",
        "    print('Mean square error train: %.5f' % mse_train )\n",
        "    print('MAPE train: %.5f' % mape_train)\n",
        "\n",
        "\n",
        "    #predictions test\n",
        "    mape_test = MAPE(y_test, pred_test)\n",
        "    mse_test = mean_squared_error(pred_test,y_test)\n",
        "    print('Mean square error test: %.5f' %mse_test )\n",
        "    print('MAPE test: %.5f' % mape_test)\n",
        "    #print('Maximum error test: %.3f' % np.max(np.linalg.norm(model.predict(X_test)-y_test)))\n",
        "    \n",
        "    return mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0_i9Hqszvr6"
      },
      "outputs": [],
      "source": [
        "#define a function that acts the gaussian process regressor\n",
        "# it returns mape, mse error on train and test \n",
        "\n",
        "def GAUS(X_train, X_test, y_train, y_test, alpha):\n",
        "    \n",
        "    #second model\n",
        "    kernel = DotProduct() + WhiteKernel()\n",
        "    model = GaussianProcessRegressor(kernel=kernel, alpha=alpha, random_state=0).fit(X_train, y_train)\n",
        "      \n",
        "    #compute predictions\n",
        "    pred_train= model.predict(X_train)\n",
        "    pred_test= model.predict(X_test)\n",
        "    \n",
        "    \n",
        "    #train\n",
        "    mape_train = MAPE(y_train, pred_train)\n",
        "    mse_train = mean_squared_error(pred_train,y_train)\n",
        "    \n",
        "    print('Mean square error train: %.5f' % mse_train )\n",
        "    print('MAPE train: %.5f' % mape_train)\n",
        "\n",
        "    #predictions test\n",
        "    mape_test = MAPE(y_test,pred_test)\n",
        "    mse_test = mean_squared_error(pred_test,y_test)\n",
        "    \n",
        "    print('Mean square error test: %.5f' %mse_test )\n",
        "    print('MAPE test: %.5f' % mape_test)\n",
        "   #print('Maximum error test: %.3f' % np.max(np.linalg.norm(model.predict(X_test)-y_test)))\n",
        "    \n",
        "    return mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roAvt_IM8HoF"
      },
      "source": [
        "The following functions differ for the grid shown in the plot. We will use them to plot the scatter of $(y[i], y[i+1])$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1iyU-_Hzvr6"
      },
      "outputs": [],
      "source": [
        "def plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test):\n",
        "    fig, ax = plt.subplots(1,3, figsize=(20,5))\n",
        "    \n",
        "    #train and test\n",
        "    \n",
        "    ax[0].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "    ax[0].set_yscale('log')\n",
        "    ax[0].set_xscale('log')\n",
        "    #ax[0].ticklabel_format(axis='both', style='sci',scilimits=(0,0))\n",
        "    \n",
        "    l1= ax[0].scatter(X_train,y_train, alpha=0.5, color= 'b')\n",
        "    l2=ax[0].scatter(X_train,pred_train, alpha=0.5, color='orange')\n",
        "    l3= ax[0].scatter(X_test, y_test, alpha=0.5, color= 'red')\n",
        "    l4=ax[0].scatter(X_test, pred_test, alpha=0.5, color='green')\n",
        "    ax[0].set_title('Train and test predictions with r: %s' % r)\n",
        "    ax[0].legend([l1,l2,l3, l4],[\"train real\", \"train predicted\", \"test real\", \"test predicted\"], loc= \"best\")\n",
        "    ax[0].grid(visible=True,which='both', axis='both')\n",
        "    \n",
        "    #train\n",
        "    \n",
        "    ax[1].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "    ax[1].set_yscale('log')\n",
        "    ax[1].set_xscale('log')\n",
        "    #ax[1].ticklabel_format(axis='both', style='sci',scilimits=(0,0))\n",
        "    \n",
        "    ax[1].grid(visible=True,which='both', axis='both')\n",
        "    l1= ax[1].scatter(X_train,y_train, alpha=0.5, color= 'b')\n",
        "    l2=ax[1].scatter(X_train,pred_train, alpha=0.5, color='orange')\n",
        "    ax[1].set_title('Train predictions with r: %s' % r)\n",
        "    ax[1].legend([l1, l2],[\"real\", \"predicted\"], loc= \"best\")\n",
        "\n",
        "        \n",
        "    #test\n",
        "    \n",
        "    ax[2].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "    ax[2].set_yscale('log')\n",
        "    ax[2].set_xscale('log')\n",
        "    \n",
        "    #ax[2].ticklabel_format(axis='both', style='sci',scilimits=(0,0))\n",
        "    ax[2].grid(visible=True,which='both', axis='both')\n",
        "    l3= ax[2].scatter(X_test, y_test, alpha=0.5, color= 'red')\n",
        "    l4=ax[2].scatter(X_test, pred_test, alpha=0.5, color='green')\n",
        "    ax[2].set_title('Test predictions with r: %s' % r)\n",
        "    ax[2].legend([l3, l4],[\"real\", \"predicted\"], loc= \"best\")\n",
        "\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joGQ-4QJaiqc"
      },
      "outputs": [],
      "source": [
        "def plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test):\n",
        "\n",
        "    fig, ax = plt.subplots(1,3, figsize=(20,5))\n",
        "    \n",
        "    #train and test\n",
        "\n",
        "    ax[0].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "    ax[0].set_yscale('log') \n",
        "    ax[0].set_xscale('log')\n",
        "    \n",
        "    #ax[0].ticklabel_format(axis='both', style='sci',scilimits=(0,0))\n",
        "    l1= ax[0].scatter(X_train,y_train, alpha=0.5, color= 'b')\n",
        "    l2=ax[0].scatter(X_train,pred_train, alpha=0.5, color='orange')\n",
        "    l3= ax[0].scatter(X_test, y_test, alpha=0.5, color= 'red')\n",
        "    l4=ax[0].scatter(X_test, pred_test, alpha=0.5, color='green')\n",
        "    ax[0].set_title('Train and test predictions with r: %s' % r)\n",
        "    ax[0].legend([l1,l2,l3, l4],[\"train real\", \"train predicted\", \"test real\", \"test predicted\"], loc= \"best\")\n",
        "    ax[0].grid()\n",
        "    \n",
        "    #train\n",
        "    \n",
        "    ax[1].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "    ax[1].set_yscale('log')\n",
        "    ax[1].set_xscale('log')\n",
        "    \n",
        "    #ax[1].ticklabel_format(axis='both', style='sci',scilimits=(0,0))\n",
        "    ax[1].grid()\n",
        "    l1= ax[1].scatter(X_train,y_train, alpha=0.5, color= 'b')\n",
        "    l2=ax[1].scatter(X_train,pred_train, alpha=0.5, color='orange')\n",
        "    ax[1].set_title('Train predictions with r: %s' % r)\n",
        "    ax[1].legend([l1, l2],[\"real\", \"predicted\"], loc= \"best\")\n",
        "\n",
        "        \n",
        "    #test\n",
        "    \n",
        "    ax[2].set(xlabel='y [i]', ylabel='y [i+1]')\n",
        "    ax[2].set_yscale('log')\n",
        "    ax[2].set_xscale('log')\n",
        "    \n",
        "    #ax[2].ticklabel_format(axis='both', style='sci',scilimits=(0,0))\n",
        "    ax[2].grid()\n",
        "    l3= ax[2].scatter(X_test, y_test, alpha=0.5, color= 'red')\n",
        "    l4=ax[2].scatter(X_test, pred_test, alpha=0.5, color='green')\n",
        "    ax[2].set_title('Test predictions with r: %s' % r)\n",
        "    ax[2].legend([l3, l4],[\"real\", \"predicted\"], loc= \"best\")\n",
        "\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cklw0TG_8qGz"
      },
      "source": [
        "The following functions plot the value corresponding to each index $i$, which is the couple $(i,y[i])$. They differ for the grid representation in the plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDzl8Tbj2ZfG"
      },
      "outputs": [],
      "source": [
        "def plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test):\n",
        "    \n",
        "# plot the figure\n",
        "\n",
        "    # Create 2x2 sub plots\n",
        "    gs = gridspec.GridSpec(2, 2)\n",
        "\n",
        "    ax =pl.figure(figsize=(20,18))\n",
        "    \n",
        "    \n",
        "    ax = pl.subplot(gs[0, :]) # row 0, span all\n",
        "       \n",
        "    ax.grid(visible=True,which='both', axis='both')\n",
        "    ax.set_yscale('log')\n",
        "    l1,=ax.plot(y_train, alpha=0.5, color='b')\n",
        "    l2,=ax.plot(pred_train, alpha=0.5, color='orange')\n",
        "    l3,=ax.plot(np.arange((steps-steps*test_size), steps),y_test, alpha=0.5, color= 'red') \n",
        "    l4,=ax.plot(np.arange((steps-steps*test_size), steps),pred_test, alpha=0.5, color= 'green')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Real and predictions with r: %s' % r)\n",
        "    ax.legend([l1, l2,l3,l4],[\"real train\",\"predicted train\" ,\"real test\", \"predicted test\"], loc= \"best\")\n",
        "    \n",
        "\n",
        "    ax= pl.subplot(gs[1, 0]) # row 1, col 0\n",
        "       \n",
        "    ax.grid(visible=True,which='both', axis='both')\n",
        "    ax.set_yscale('log')\n",
        "    l1,=ax.plot(y_train, alpha=0.5, color='b')\n",
        "    l2,=ax.plot(pred_train, alpha=0.5, color='orange')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Train real and predictions with r: %s' % r)\n",
        "    ax.legend([l1, l2],[\"real train\",\"predicted train\" ], loc= \"best\")\n",
        "    \n",
        "    ax = pl.subplot(gs[1, 1]) # row 1, col 1\n",
        "       \n",
        "    ax.grid(visible=True,which='both', axis='both')\n",
        "    ax.set_yscale('log')\n",
        "    l3,=ax.plot(np.arange((steps-steps*test_size), steps),y_test, alpha=0.5, color= 'red') \n",
        "    l4,=ax.plot(np.arange((steps-steps*test_size), steps),pred_test, alpha=0.5, color= 'green')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Test real and predictions with r: %s' % r)\n",
        "    ax.legend([l3,l4],[\"real test\", \"predicted test\"], loc= \"best\")\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test):\n",
        "    \n",
        "    # plot the figure\n",
        "\n",
        "    # Create 2x2 sub plots\n",
        "    gs = gridspec.GridSpec(2, 2)\n",
        "    ax =pl.figure(figsize=(20,18))\n",
        "    \n",
        "    \n",
        "    ax = pl.subplot(gs[0, :]) # row 0, span all\n",
        "       \n",
        "    ax.grid()\n",
        "    ax.set_yscale('log')\n",
        "    l1,=ax.plot(y_train, alpha=0.5, color='b')\n",
        "    l2,=ax.plot(pred_train, alpha=0.5, color='orange')\n",
        "    l3,=ax.plot(np.arange((steps-steps*test_size), steps),y_test, alpha=0.5, color= 'red') \n",
        "    l4,=ax.plot(np.arange((steps-steps*test_size), steps),pred_test, alpha=0.5, color= 'green')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Real and predictions with r: %s' % r)\n",
        "    ax.legend([l1, l2,l3,l4],[\"real train\",\"predicted train\" ,\"real test\", \"predicted test\"], loc= \"best\")\n",
        "    \n",
        "\n",
        "    ax= pl.subplot(gs[1, 0]) # row 1, col 0\n",
        "       \n",
        "    ax.grid()\n",
        "    ax.set_yscale('log')\n",
        "    l1,=ax.plot(y_train, alpha=0.5, color='b')\n",
        "    l2,=ax.plot(pred_train, alpha=0.5, color='orange')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Train real and predictions with r: %s' % r)\n",
        "    ax.legend([l1, l2],[\"real train\",\"predicted train\" ], loc= \"best\")\n",
        "    \n",
        "    ax = pl.subplot(gs[1, 1]) # row 1, col 1\n",
        "       \n",
        "    ax.grid()\n",
        "    ax.set_yscale('log')\n",
        "    l3,=ax.plot(np.arange((steps-steps*test_size), steps),y_test, alpha=0.5, color= 'red') \n",
        "    l4,=ax.plot(np.arange((steps-steps*test_size), steps),pred_test, alpha=0.5, color= 'green')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Test real and predictions with r: %s' % r)\n",
        "    ax.legend([l3,l4],[\"real test\", \"predicted test\"], loc= \"best\")\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lCZhKXfHEOzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWV8bYOA9Bfe"
      },
      "source": [
        "It can be interesting to zoom in the function representation, thanks to the zoom function mentioned below it is possible to zoom the plot and confront the prediction with the real valules graphically, in any interval of both axes.\n",
        "\n",
        "It will be necessary to insert the intervals on both axes where we want to zoom in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztCcprIIjYoK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def zoomplotter_steps(range_low_lim_x, range_up_lim_x,range_low_lim_y, range_up_lim_y,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test):\n",
        "    # Create main container \n",
        "    fig, ax = plt.subplots(figsize=(20,5))\n",
        "    plt.subplots_adjust(bottom = 0., left = 0, top = 1., right = 1)\n",
        "    ax.set_yscale('log')\n",
        "    ax.set_xlim(range_low_lim_x, range_up_lim_x)\n",
        "    ax.set_ylim(range_low_lim_y, range_up_lim_y)\n",
        "    l1,=ax.plot(y_train,alpha=0.5, color='b')#,\"r--\")\n",
        "    l2,=ax.plot(pred_train,alpha=0.5, color='orange')\n",
        "    l3,=ax.plot(np.arange((steps-steps*test_size), steps),y_test, alpha=0.5, color='red') \n",
        "    l4,=ax.plot(np.arange((steps-steps*test_size), steps),pred_test, alpha=0.5, color= 'green')\n",
        "    ax.set(xlabel='Index', ylabel='Function value')\n",
        "    ax.set_title('Zoom of the plot real and predictions with r: %s' % r)\n",
        "    ax.legend([l1, l2,l3,l4],[\"real train\",\"predicted train\" ,\"real test\", \"predicted test\"], loc= \"best\")\n",
        "    ax.grid()\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BsbCR4I9phA"
      },
      "source": [
        "This function shows how the size of the train and test (so their proportion) impacts on the predictions of the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dWywtSGDd5i"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot train size vs mse error\n",
        "\n",
        "def trainVSmse(steps, sizes, mse_train_list, mse_test_list):\n",
        "  fig, ax = plt.subplots(figsize=(7,7))\n",
        "  array_sizes=np.array(sizes)*100\n",
        "  l1,= ax.plot(array_sizes,mse_train_list)\n",
        "  l2,=ax.plot(array_sizes, mse_test_list)\n",
        "  ax.ticklabel_format(axis='y', style='sci',scilimits=(0,0))\n",
        "  ax.set(xlabel='Dataset percentage of the test (%)', ylabel='MSE error')\n",
        "  plt.title('Test size vs MSE')\n",
        "  \n",
        "  ax.legend([l1, l2],[\"MSE train\",\"MSE test\"], loc= \"best\")\n",
        "  ax.grid(visible=True,which='both', axis='both')\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOe7wbC9svh"
      },
      "source": [
        "When we tune the alpha parameter, thanks to this plot it is possible to see how the alpha value impacts on the MSE error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQsxZ0vEdcvJ"
      },
      "outputs": [],
      "source": [
        "# plot alpha and MSE error\n",
        "\n",
        "def alphaVSmse(alphas, mse_train_list, mse_test_list):   \n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(7,7))\n",
        "  l1,=ax.plot(alphas, mse_train_list,alpha=0.5)\n",
        "  l2,=ax.plot(alphas, mse_test_list,alpha=0.5)\n",
        "  plt.legend([l1, l2],[\"MSE train\", \"MSE test\"], loc= \"best\")\n",
        "  ax.ticklabel_format(axis='y', style='sci',scilimits=(0,0))\n",
        "  ax.set(xlabel='alpha', ylabel='MSE')\n",
        "  plt.title('Alphas vs MSE')\n",
        "  plt.grid(visible=True,which='both', axis='both')\n",
        "  fig.tight_layout()\n",
        "  plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQSkikW3-e7F"
      },
      "source": [
        "Building a data frame where we can insert the values of the experiments can be usefull to then confron all the results, and have a general overview.\n",
        "\n",
        "What we would like to observe are: the $r$ value which impacts on the periodicity, $steps$ which is the number of points of the dataset generated, $test \\_ size$ the way we splitted the original dataset, the $model$ we used (which is adapted to the periodicity of the generated function), $\\alpha$ parameter, the errors o both training and set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu3RqEg5zvr6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calling DataFrame constructor  \n",
        "def DataFrameConstructor(r, steps, test_size,model, alpha,  mse_train, mse_test ):\n",
        "## list of strings\n",
        "    dict={'r':[r],'steps':[steps],'test_size':[test_size],'model':[model],'alpha':[alpha], 'mse_train':[mse_train],'mse_test': [mse_test] }  \n",
        "\n",
        "    df = pd.DataFrame(dict)\n",
        "    #display(df)\n",
        "    return df "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W51Lq_LL61sW"
      },
      "source": [
        "It can be interesting to inject some noise and see how it can impact our predictions. To test the robustnesss of the models in the different situations (such as the different periodicity of the dataset, the different kernel used for the predictions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS0TcOsozvr7"
      },
      "outputs": [],
      "source": [
        "# add noise function\n",
        "\n",
        "def noiseadder(steps, dataset_X, dataset_y):\n",
        "    noise = np.random.normal(3,4,steps)\n",
        "\n",
        "    dataset_y_noisy= dataset_y+ noise\n",
        "    dataset_X_noisy=np.array([elem[0] +noise for elem in dataset_X])\n",
        "    \n",
        "\n",
        "    return dataset_X_noisy, dataset_y_noisy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DunBVYkf_eZs"
      },
      "source": [
        "Now we start the experiments.\n",
        "\n",
        "First we initialize the data frame, where we will insert the experiments results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqIHo_kCIni9"
      },
      "outputs": [],
      "source": [
        "# initialize data frame\n",
        "dict={'r':[],'steps':[],'test_size':[],'model':[],'alpha':[],  'mse_train':[],'mse_test': [] }  \n",
        "#empty data frame:\n",
        "df = pd.DataFrame(dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Periodic and linear experiments"
      ],
      "metadata": {
        "id": "DT6Cjl15DBZ5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xETH6Ejh-G_g"
      },
      "source": [
        "\n",
        "### $r=0.5$ and $50$ steps\n",
        "\n",
        "Let us generate the dataset with r=0.5, and 50 steps.\n",
        "\n",
        "\n",
        "When r is small (less than one, to be specific), the population heads towards 0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e35PSEH-A2qi"
      },
      "outputs": [],
      "source": [
        "r =0.5\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter1(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDrVM9xIzvr8"
      },
      "outputs": [],
      "source": [
        "#parameters\n",
        "alpha= 0.1\n",
        "kernel= 'linear'\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-5,1e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgjgvILqzvr-"
      },
      "source": [
        "### Comments\n",
        "When r is small (less than one, to be specific), the population heads towards 0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHQyO8UO2ZfJ"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "#display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4M8sBExJOok"
      },
      "source": [
        "we have been testing different kernels, but the linear one better suits the linearity of the function we have to predict, so we will avoid experimets with the other kernels sincethe results are worst.\n",
        "\n",
        "As a reminder the tested kernels are the following:\n",
        "- kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "- kernel= 1.0 * RBF(1.0)\n",
        "The code is the same of the ablove box, but changing the kernel (If you wish to see the result, you can change it)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCh3xETDKMHJ"
      },
      "source": [
        "It is now interesting to see what happens changing the number of points of the dataset. Below the results generating a dataset of 1000 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDQAD8ukAcN0"
      },
      "source": [
        "### $r =0.5$ and $steps=1000$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCau2_juBHwg"
      },
      "outputs": [],
      "source": [
        "r =0.5\n",
        "steps=1000\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlc2Awv8zFvT"
      },
      "outputs": [],
      "source": [
        "DatasetPlotter2(r, steps, dataset_X, dataset_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn_5KMzEKLDu"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "kernel= 'linear'\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size,model, alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "    \n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps1(steps,r,test_size,X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-5,1e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCvkxx_PKhMu"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "\n",
        "#display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crGk31JN2ZfL"
      },
      "source": [
        "### tuning the parameter alpha\n",
        "An other interesting point is to consider some regularization parameters to better understand in the linear example which is very simple, how selecting the proper parameter can impact on the forecasting accuracy (mse for example)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzGHEFN7BPzF"
      },
      "outputs": [],
      "source": [
        "r =0.5\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter1(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXNu0yyY2ZfL"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.00001, 2, 0.01)\n",
        "kernel= 'linear'\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    #define one for each alpha\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "\n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "    \n",
        "      mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "      \n",
        "\n",
        "      \n",
        "      dr= DataFrameConstructor(r, steps, test_size,model, alpha, mse_train, mse_test)\n",
        "      df= df.append(dr)\n",
        "      \n",
        "      #save errors in arrays\n",
        "      mape_train_list.append(mape_train)\n",
        "      mape_test_list.append(mape_test)\n",
        "      \n",
        "      mse_train_list.append(mse_train)\n",
        "      mse_test_list.append(mse_test)\n",
        "\n",
        "      # plot the figure!\n",
        "      # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "      # plotter_steps2(steps,r,test_size,X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "alphaVSmse(alphas, mse_train_list, mse_test_list)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhHl2ahTbuod"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4cdJkp9Nmd1"
      },
      "source": [
        "### $r=2.5$, $steps= 50$\n",
        "As r is increased to 2.5, a stable population is reached\n",
        "\n",
        "This is called a period one trajectory because it takes one iteration to return to the starting population size. Because period one occurs when $x_{n+1}=x_{n}$, we can algebraically determine the population values reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl4591IHBZZ3"
      },
      "outputs": [],
      "source": [
        "r=2.5\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXZyQXQ2EG5S"
      },
      "outputs": [],
      "source": [
        "    # plot the figure!\n",
        "   \n",
        "    l1= plt.scatter(flat_dataset_X,dataset_y, alpha=0.5)\n",
        "    plt.xlabel('y [i]')\n",
        "    plt.ylabel('y [i+1]')\n",
        "\n",
        "    plt.legend([l1],[\"datset\"], loc= \"best\")\n",
        "    plt.title('Dataset plot with r: %s' % r)\n",
        "    plt.grid()\n",
        "    plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gzy68RszvsA"
      },
      "outputs": [],
      "source": [
        "\n",
        "#alphas= np.arange(0.00001, 2, 0.01)\n",
        "sizes=(0.1,0.2,0.3, 0.5)\n",
        "kernel='linear'\n",
        "alpha=0.1\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    kernel=DotProduct() + WhiteKernel() #TBD\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test, kernel, alpha)\n",
        "\n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size,model, alpha, mse_train, mse_test)\n",
        "    df= df.append(dr) \n",
        "\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # plot the figure!\n",
        "    #plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTnV_DzR2ZfL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# display the data frame    \n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWa5EqX_Nu_2"
      },
      "source": [
        "### $r=3.1$, $steps= 50$\n",
        "comment: at $r=3.1$ the population fluctuates, returning to the starting point every other year instead of every year. This is called period 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxDXq33NEBY4"
      },
      "outputs": [],
      "source": [
        "r =3.1\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYYvx7qqzsZg"
      },
      "outputs": [],
      "source": [
        "DatasetPlotter1(r, steps, dataset_X, dataset_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4XjiFaXkxBM"
      },
      "outputs": [],
      "source": [
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "#alphas= np.arange(0.00001, 2, 0.01)\n",
        "alpha=0.01\n",
        "#kernel= ExpSineSquared(length_scale=1, periodicity=2)#TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "#kernel= ExpSineSquared(length_scale=1, periodicity=2)#TBD\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "   \n",
        "    dr= DataFrameConstructor(r, steps, test_size,model, alpha, mse_train, mse_test)\n",
        "    df= df.append(dr) \n",
        "    \n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)    \n",
        "    \n",
        "    # plot the figure!\n",
        "    \n",
        "    \n",
        "    plotter1(X_train, X_test, y_train, y_test,pred_train,pred_test)\n",
        "    \n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "    zoomplotter_steps(1,10,5e-1,8e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI_4r4P52ZfN"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "\n",
        "#display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKSWMeLEJf0"
      },
      "source": [
        "r =3.1\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQC0994xAE2y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "#alphas= np.arange(0.00001, 2, 0.01)\n",
        "alpha=0.01\n",
        "\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "#kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "kernel= ExpSineSquared(length_scale=1, periodicity=2)#TBD\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size,model, alpha, mse_train, mse_test)\n",
        "    df= df.append(dr) \n",
        "    \n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)  \n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test,pred_train,pred_test)\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    zoomplotter_steps(1,10,5e-1,9e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePY5LrT7AExz"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "#display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SoH7DaWEOaE"
      },
      "source": [
        "r =3.1\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_Il6toizvsC"
      },
      "outputs": [],
      "source": [
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "alphas= np.arange(0.00001, 2, 0.01)\n",
        "\n",
        "#kernel= ExpSineSquared(length_scale=1, periodicity=2)#TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "#kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "kernel= ExpSineSquared(length_scale=1, periodicity=2)#TBD\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "\n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "    \n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "        print('test size :',test_size)\n",
        "      \n",
        "\n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "        # dr= DataFrameConstructor(r, steps, test_size,model, mse_train, mse_test)\n",
        "        # df= df.append(dr) \n",
        "    \n",
        "\n",
        "        # # comment to avoid a too long output\n",
        "        # # plot the figure!\n",
        "        # plotter(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "        \n",
        "        # plotter_steps(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "        \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)\n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StlS2upn2ZfN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fQO8fI-2ZfO"
      },
      "outputs": [],
      "source": [
        "# # display the data frame    \n",
        "# display(df1)\n",
        "# display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGw39eJbzvsD"
      },
      "source": [
        "### r= 3.5\n",
        "at $r=3.5$, the trajectory is period 4, as it takes 4 iterations for the population to return to its original position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIzp-fiXES8Z"
      },
      "outputs": [],
      "source": [
        "r=3.5\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter1(r, steps, dataset, dataset_y)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLRosadY2ZfO"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.00001, 1, 0.01)\n",
        "\n",
        "#kernel= ExpSineSquared(length_scale=1, periodicity=4)#TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "\n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "        \n",
        "        # dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "        # df= df.append(dr)\n",
        "            \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "        \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)  \n",
        "\n",
        "        # # comment to avoid too long output\n",
        "        # # plot the figure!\n",
        "        # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "      \n",
        "    \n",
        "    \n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuLaZ4dhcC0c"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adbt2yQnEXNs"
      },
      "source": [
        "r=3.5\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpvF29QkzvsD"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.001, 1, 0.01)\n",
        "\n",
        "kernel= ExpSineSquared(length_scale=1, periodicity=4)#TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "#kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "        \n",
        "        # # plot the figure!\n",
        "        # plotter(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "        \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)  \n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list)     \n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blwzUn9k2ZfQ"
      },
      "outputs": [],
      "source": [
        "# # display the data frame    \n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xyCyhGyzvsE"
      },
      "source": [
        "r=3.5\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fax5pOO4zvsE"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.001, 1, 0.01)\n",
        "kernel= ExpSineSquared(length_scale=1, periodicity=2)\n",
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "\n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test,kernel, alpha)\n",
        "        # dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "        # df= df.append(dr)\n",
        "            \n",
        "\n",
        "\n",
        "        # # plot the figure!\n",
        "        # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size,X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "\n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)  \n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m16e_sOC2ZfR"
      },
      "outputs": [],
      "source": [
        "# # display the data frame    \n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rpcUCsREfx5"
      },
      "source": [
        "r=3.5\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IblbYuo3zvsG"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.001, 1, 0.01)\n",
        "#kernel= fixed in the gauss model #TBD\n",
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "     \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = GAUS( X_train, X_test, y_train, y_test, alpha)\n",
        "\n",
        "    \n",
        "        # dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "        # df= df.append(dr)\n",
        "\n",
        "        # # plot the figure!\n",
        "        # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "        \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)\n",
        "    \n",
        "      \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1dBJt6o2ZfR"
      },
      "outputs": [],
      "source": [
        "# # display the data frame    \n",
        "\n",
        "# display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tok2jqVXSU9v"
      },
      "outputs": [],
      "source": [
        "alpha= 0.1\n",
        "kernel= ExpSineSquared(length_scale=1, periodicity=4)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    #Select an appropriate value for alpha\n",
        "    #for alpha in arange(0.00001, 1, 0.01):\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,8e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOSIWJ-RSUwf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rQNaCHizvsH"
      },
      "source": [
        "# Aperiodic trajectories in the logistic map\n",
        "For $r=3.7$, the (prime) period is longer than the iterations plotted and is actually infinite, and therefore the system is called aperiodic. To restate, this means that previous values of the logistic equation are never revisited for an aperiodic $r$ value. The ensuing plot has points that look random but are deterministic. The formation of aperiodic behavior from a deterministic system is termed mathematical chaos.\n",
        "\n",
        "### Remark: \n",
        "As demonstrated by Lorenz in his pioneering work on flow, nonlinear dissipative systems capable of aperiodic behavior are extremely sensitive to initial conditions such that long-range behavior is impossible to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKs7XNW7Eiqi"
      },
      "outputs": [],
      "source": [
        "r =3.7\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter1(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXT6tH3D8AwE"
      },
      "outputs": [],
      "source": [
        "# alpha= 0.1\n",
        "# kernel= RationalQuadratic(length_scale=1.0, alpha=1.5) #TBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia5NFPeYrWj7"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "kernel= RationalQuadratic(length_scale=1.0, alpha=1.5) #TBD\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "  \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFLD50nBElrQ"
      },
      "source": [
        "r =3.7\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK-XJwqzrjaC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "alpha= 0.1\n",
        "kernel= RationalQuadratic(length_scale=0.3, alpha=0.1) #TBD\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = GAUS(X_train, X_test, y_train, y_test, alpha)\n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXtO5G3gEo0_"
      },
      "source": [
        "r =3.7\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCL8YQQfr92S"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "kernel= RationalQuadratic(length_scale=0.4, alpha=0.1) #TBD \n",
        "#kernel= RationalQuadratic(length_scale=1.0, alpha=5.5) #TBD\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "      \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEGlrIyBErvq"
      },
      "source": [
        "r =3.7\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PiM92tG02Ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "#kernel= RationalQuadratic(length_scale=1.0, alpha=1.5) #TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "#kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "kernel= 1.1 * RBF(0.5)\n",
        "#kernel= 'linear'\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obgVAiqMEuxg"
      },
      "source": [
        "r =3.7\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s63G0nOOtcez"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "kernel= ExpSineSquared(length_scale=1, periodicity=4)#TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "#kernel=  1.0 * Matern(length_scale=1.0, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Tiq2IoExQ-"
      },
      "source": [
        "r =3.7\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWAQ3fFDttO2"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "#kernel= ExpSineSquared(length_scale=1, periodicity=4)#TBD\n",
        "#kernel=DotProduct() + WhiteKernel() \n",
        "kernel=  1.1 * Matern(length_scale=0.5, nu=1.5)\n",
        "#kernel= 1.0 * RBF(1.0)\n",
        "#kernel= 'linear'\n",
        "\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "   \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    zoomplotter_steps(1,10,8e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe0x7-_BE0-U"
      },
      "source": [
        "r=3.7\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF9ZO2ATzvsI"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.00001, 1, 0.01)\n",
        "kernel= RationalQuadratic(length_scale=0.4, alpha=0.1)  #TBD\n",
        "#kernel=  1.1 * Matern(length_scale=0.5, nu=1.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "     \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "\n",
        "\n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value', alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test,kernel, alpha)\n",
        "\n",
        "        # dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "        # df= df.append(dr)\n",
        "\n",
        "        # # plot the figure!\n",
        "        # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "        \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)    \n",
        "    \n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E_k-7Br2ZfS"
      },
      "outputs": [],
      "source": [
        "# display the data frame    \n",
        "# display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOtFzfHmE4Js"
      },
      "source": [
        "r=3.7\n",
        "steps=50\n",
        "dataset, dataset_y= Dataset_generator(r, steps)\n",
        "flat_dataset_X = np.array([elem[1] for elem in dataset])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMv-5QdvzvsI"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.001, 1, 0.01)\n",
        "#kernel= RationalQuadratic(length_scale=0.4, alpha=0.1)  #TBD\n",
        "kernel=  1.1 * Matern(length_scale=0.5, nu=1.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "     \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "\n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test,kernel, alpha)\n",
        "        \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "    \n",
        "            \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)  \n",
        "\n",
        "        # dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "        # df= df.append(dr)\n",
        "        # # plot the figure!\n",
        "        # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size,X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "    \n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ROC1-a52ZfT"
      },
      "outputs": [],
      "source": [
        "# # display the data frame    \n",
        "\n",
        "# display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSEOBgoGG_wf"
      },
      "source": [
        "# r=3.7, steps= 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Ni3wMPQi0N"
      },
      "outputs": [],
      "source": [
        "r =3.7\n",
        "steps=200\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter1(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn1Heo7szvsJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "alpha= 0.1\n",
        "kernel= RationalQuadratic(length_scale=0.4, alpha=0.1)  \n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "alpha= 0.1\n",
        "#kernel= RationalQuadratic(length_scale=0.4, alpha=0.1)  \n",
        "kernel= 1.1 * RBF(0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps1(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,9e-1,3e-1,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ],
      "metadata": {
        "id": "qbfhlYcvSR6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### r=4"
      ],
      "metadata": {
        "id": "0YAolZ5FRQMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPqOAO12HSdu"
      },
      "outputs": [],
      "source": [
        "r =4\n",
        "steps=50\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter2(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsVhZ9eiJZ4E"
      },
      "outputs": [],
      "source": [
        "alpha= 0.1\n",
        "kernel= RationalQuadratic(length_scale=0.1, alpha=0.1)  \n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-3,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgfNka8WJZwG"
      },
      "outputs": [],
      "source": [
        "kernel=  1.0 * Matern(length_scale=1.0, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-3,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernel=  6.0 * Matern(length_scale=1.0, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-3,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)    "
      ],
      "metadata": {
        "id": "Gpj8G57Qda6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwv5NhRTWaAz"
      },
      "outputs": [],
      "source": [
        "\n",
        "alphas= np.arange(0.001, 1, 0.01)\n",
        "#kernel= RationalQuadratic(length_scale=0.4, alpha=0.1)  #TBD\n",
        "kernel=  6 * Matern(length_scale=0.5, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "     \n",
        "    #define\n",
        "    mape_train_list=[]\n",
        "    mape_test_list=[] \n",
        "    mse_train_list=[]\n",
        "    mse_test_list=[] \n",
        "\n",
        "    #Select an appropriate value for alpha\n",
        "    for alpha in alphas:\n",
        "        print('alpha has value: %.3f' % alpha)\n",
        "    \n",
        "        mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE( X_train, X_test, y_train, y_test,kernel, alpha)\n",
        "        \n",
        "        #save errors in arrays\n",
        "        mape_train_list.append(mape_train)\n",
        "        mape_test_list.append(mape_test)\n",
        "    \n",
        "            \n",
        "        mse_train_list.append(mse_train)\n",
        "        mse_test_list.append(mse_test)  \n",
        "\n",
        "        # dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "        # df= df.append(dr)\n",
        "        # # plot the figure!\n",
        "        # plotter1(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "        # plotter_steps1(steps,r,test_size,X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "    \n",
        "    \n",
        "    alphaVSmse(alphas, mse_train_list, mse_test_list) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4vaD0ZNJZoB"
      },
      "outputs": [],
      "source": [
        "r =4\n",
        "steps=200\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter2(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zzNLMbyNLHH"
      },
      "outputs": [],
      "source": [
        "kernel=  2.0 * Matern(length_scale=1.0, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-2,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5ZuWmj_NTKp"
      },
      "outputs": [],
      "source": [
        "kernel=  2.0 * Matern(length_scale=0.5, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "alpha=0.1\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-2,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Sc1HyfedrJ"
      },
      "outputs": [],
      "source": [
        "kernel=  4.0 * Matern(length_scale=0.5, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "alpha=0.1\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-2,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqbu_E9eeddO"
      },
      "outputs": [],
      "source": [
        "kernel=  6.0 * Matern(length_scale=0.5, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "alpha=0.1\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-2,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuyuDCIsZZkH"
      },
      "outputs": [],
      "source": [
        "#print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WG23nReV8F7"
      },
      "outputs": [],
      "source": [
        "r =4\n",
        "steps=1000\n",
        "dataset_X, dataset_y= Dataset_generator(r, steps)\n",
        "DatasetPlotter2(r, steps, dataset_X, dataset_y)\n",
        "flat_dataset_X = np.array([elem[0] for elem in dataset_X])[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SjA1D5kV7-2"
      },
      "outputs": [],
      "source": [
        "kernel=  6.0 * Matern(length_scale=0.5, nu=0.5)\n",
        "sizes= (0.1,0.2,0.3, 0.5)\n",
        "alpha=0.1\n",
        "#define\n",
        "mape_train_list=[]\n",
        "mape_test_list=[] \n",
        "mse_train_list=[]\n",
        "mse_test_list=[] \n",
        "\n",
        "\n",
        "\n",
        "for test_size in sizes:\n",
        "    print('test size :',test_size)\n",
        "    X_train, X_test, y_train, y_test= split(flat_dataset_X, dataset_y,test_size)\n",
        "    \n",
        "    mape_train, mape_test, mse_train, mse_test, model, pred_train, pred_test = RIDGE(X_train, X_test, y_train, y_test, kernel,alpha)\n",
        "    \n",
        "    \n",
        "    \n",
        "    dr= DataFrameConstructor(r, steps, test_size, model,alpha, mse_train, mse_test)\n",
        "    df= df.append(dr)\n",
        "\n",
        "    #save errors in arrays\n",
        "    mape_train_list.append(mape_train)\n",
        "    mape_test_list.append(mape_test)\n",
        "    \n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)\n",
        "    \n",
        "    # plot the figure!\n",
        "    plotter2(X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "\n",
        "    plotter_steps2(steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "\n",
        "    zoomplotter_steps(1,10,1e-2,1e-0,steps,r,test_size, X_train, X_test, y_train, y_test, pred_train, pred_test)\n",
        "    \n",
        "trainVSmse(steps, sizes, mse_train_list, mse_test_list)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7kjQzwO1AnI"
      },
      "source": [
        "Uncommenting the following lines, we download the dataframe of the result, after convering it in a csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa1__-uAdqGV"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('Experiments.csv',index=False)\n",
        "# from google.colab import files\n",
        "# files.download('Experiments.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This work is attached to the Thesis document (Learning dynamical systems with kernels). \n",
        "\n",
        "In the thesis, theoretical explanations as well as comments on the results are presented."
      ],
      "metadata": {
        "id": "OrxETgV1xfg6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTaGTb_gjBHe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "crGk31JN2ZfL",
        "q4cdJkp9Nmd1",
        "OGw39eJbzvsD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}